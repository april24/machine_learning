{"name":"Machine learning","tagline":"","body":"---\r\ntitle: \"Human Activity Recognition\"\r\nauthor: \"Rong Chen\"\r\noutput: html_document\r\n---\r\n\r\n## Introduction\r\nIn this project, I used data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.My goal of this project is to predict the manner in which they did the exercise,which is the \"classe\" variable in the training set. \r\n\r\n\r\n## Data Cleaning\r\nFirst,I loaded the data and cleaned the data.After removing all the variables with missing values, I only leave the variables about\"belt\", \"forearm\", \"arm\", \"and dumbell\".\r\n```{r}\r\nlibrary(lattice);library(ggplot2);library(caret)\r\npml<- read.table(\"./pml-training.csv\",sep = \",\", header = TRUE)\r\npml<-subset(pml,select=-c(X:num_window,kurtosis_roll_belt:var_yaw_belt,var_accel_arm:var_yaw_arm,\r\n                          kurtosis_roll_arm:amplitude_yaw_arm,kurtosis_roll_dumbbell:amplitude_yaw_dumbbell,\r\n                          var_accel_dumbbell:var_yaw_dumbbell,kurtosis_roll_forearm:amplitude_yaw_forearm,\r\n                          var_accel_forearm:var_yaw_forearm))\r\n```\r\nThen I ran cor() matrix to eliminate highly correlated variables and removed some highly correlated variables.\r\n```{r,results='hide'}\r\nM<-abs(cor(pml[,-53]))\r\ndiag(M)<-0\r\nwhich(M>0.8,arr.ind=T)\r\n```\r\n\r\n```{r}\r\npml<-subset(pml,select=-c(yaw_belt,total_accel_belt,accel_belt_x,accel_belt_y,accel_belt_z,magnet_belt_x,\r\n                          gyros_arm_y,magnet_arm_x,magnet_arm_z,gyros_dumbbell_z,gyros_forearm_z,\r\n                          accel_dumbbell_x,accel_dumbbell_z))\r\n```\r\n\r\n## Cross Validation \r\nFirst I created training and testing  sets.\r\n```{r}\r\nset.seed(1234)\r\ninTrain<-createDataPartition(y=pml$classe,p=0.7,list=FALSE)\r\ntraining<-pml[inTrain,]\r\ntesting<-pml[-inTrain,]\r\n```\r\n\r\nThen I fitted 4 models by using the training set, then I Evaluated on the test set. At last I calculated the accuracy of each model.\r\n\r\n\r\n#####1.Prediction with trees\r\n```{r}\r\nlibrary(rpart)\r\nmodel1<-train(classe~.,method =\"rpart\",data=training)\r\nprediction1<-predict(model1,testing)\r\nconfusionMatrix(prediction1,testing$classe)$overall\r\n```\r\n#####2.Support vector machine\r\n```{r}\r\nlibrary(e1071)\r\nmodel2<-svm(classe ~ ., data = training)\r\nprediction2<-predict(model2,testing)\r\nconfusionMatrix(prediction2,testing$classe)$overall\r\n```\r\n#####3.Random forests\r\n```{r}\r\nlibrary(randomForest)\r\nmodel3<-randomForest(classe ~ ., data = training)\r\nprediction3<-predict(model3,testing)\r\nconfusionMatrix(prediction3,testing$classe)$overall\r\n```\r\n#####4.Boosting with trees\r\n```{r}\r\nlibrary(survival);library(splines);library(parallel);library(plyr);library(gbm)\r\nmodel4<-train(classe~.,method =\"gbm\",data=training,verbose=FALSE)\r\nprediction4<-predict(model4,testing)\r\nconfusionMatrix(prediction4,testing$classe)$overall\r\n```\r\n\r\n## Conclustion\r\nWe can compare these four modles,and find out the model3(Random Forests) is the best model, as it has 99.524% accuracy. So I will choose model3.\r\n```{r}\r\ntable(prediction3,testing$classe)\r\n```\r\nThe out of sample error for the testing set is 1-99.524%=0.476%\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}